<!DOCTYPE html>

<!-- 
  Hi! Thanks for checking out this website. 
  I made it myself! 
  This website was made by hand. 
  I intentionally haven't minified anything so you can see how it all fits together.
-->

<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="author" content="Clayton Ramsey" />
    <meta name="description" content="TODO" />
    <meta name="keywords" content="robots, Rust, SIMD" />

    <title>Making robots plan faster with SIMD and Rust</title>

    <link rel="stylesheet" type="text/css" href="/assets/main.css" />
    <link rel="stylesheet" href="/assets/hljs.css" />
    <link rel="icon" href="/assets/img/favicon.ico" />

    <script src="/assets/js/highlight.min.js"></script>
    <script id="MathJax-script" async src="/assets/js/mathjax/tex-mml-chtml.js"></script>

    <script>
      hljs.highlightAll();
    </script>
  </head>
  <body>
    <header>
      <nav>
        <a href="/index.html">Home</a>
        <a href="/about.html">About</a>
        <a href="/blog.html">Blog</a>
        <a href="/recipes.html">Recipes</a>
      </nav>
    </header>
    <h1>Making robots plan in real-time with SIMD</h1>
    <p>
      I'm now wrapping up my first "real" research project of my my Ph.D., which is both exciting
      and very stressful at the same time. I got to experiment with a lot of really cool things, but
      most of them didn't actually work. I'm writing this blog post as a collection of the story
      behind the paper, where I get to explain all the things I tried that didn't work out, as well
      as to share the untold story of the paper.
    </p>
    <p>
      If you want to skip straight to just reading the final paper, check it our on arXiV
      <strong>INSERT ARXIV LINK!!!!</strong>.
    </p>
    <h2>The problem at hand</h2>
    <p>
      A few months ago, two postdocs in my lab published a
      <a
        href="https://arxiv.org/abs/2309.14545v2?trk=feed_main-feed-card_reshare_feed-article-content"
        >paper</a
      >
      demonstrating dramatic speedups by using SIMD and precompilation for motion planning. However,
      their approach assumed that they had access to a primitive representation of the environment,
      which is rarely the case in reality. In many applications, robots must plan using their
      observed sensor data - namely, pointclouds.
    </p>
    <p>
      In most sampling-based planning algorithms, such as RRT and PRM, collision checking is
      far-and-away the most commonly called (and therefore the most expensive) subroutine. This
      means that we have to develop methods for efficiently checking whether our robot is in
      collision with a pointcloud.
    </p>
    <figure style="display: flex">
      <div>
        <img src="/assets/img/afftree/ur5.png" />
        <figcaption>A Universal Robots model UR-5e robot arm.</figcaption>
      </div>
      <div>
        <img src="/assets/img/afftree/ur5_ball.svg" />
        <figcaption>A conservative spherical approximation of the UR-5e's geometry.</figcaption>
      </div>
    </figure>
    <strong
      >TODO: use one of our own images instead of this (which I got from the UR-5 website)</strong
    >
    <p>
      We can start by assuming that our robot can be modeled as a set of balls over some distance
      metric. Using the \(L^2\) distance metric, these balls are spheres, which meshes conveniently
      with sphere-hierarchy representations of robot geometry. This lets us neatly reduce the
      problem of collision-checking all kinds of robot geometries into one simple case: checking
      whether a some set of spheres collides with a set of points. In addition to that, we would
      like to be able to do our collision checking in parallel at an instruction level to radically
      improve our performance.
    </p>
    <h2>Review: \(k\)-d trees</h2>
    <p>
      There's a simple solution to our collision-checking problem using a nearest-neighbors data
      structure. Given a set of points \(P\) in the pointcloud, construct a nearest-neighbor data
      structure over \(P\). Then, whenever we have to check whether some sphere with center \(x\)
      and radius \(r\) is in collision, we find the closest point \(p\) in \(P\) to \(x\), and check
      whether the distance from \(x\) to \(p\) is greater than \(r\).
    </p>
    <p>
      The canonical approach to computing nearest-neighbors is a \(k\)-d tree - a class of space
      partitioning tree. There are many formulations, but I'll use a median-partitioning tree in
      this case.
    </p>
    <p>
      At each branch of a \(k\)-d tree, we split the the space into two sub-volumes, each containing
      the same number of points, based on the median value along one dimension. For instance, if we
      wanted to split the points \(\{(2, 3), (4, 4)\}\) along the first dimension, we'd choose a
      split value of 3, and if we were splitting along the second dimension, we'd choose a split of
      3.5. For efficiency, we'll have our tree split first on dimension 0 (\(x\)), then dimension 1
      (\(y\)), and so on, until looping back around to dimension 0.
    </p>
    <figure>
      <img src="/assets/img/afftree/kdt_partition.svg" class="night-invert" />
      <figcaption>The partitioned cells of a \(k\)-d tree.</figcaption>
    </figure>
    <p>
      When querying the nearest neighbor, we first do a quick binary search of the tree to find a
      candidate closest point. Next, we perform a branch-and-bound search of every other subtree,
      escaping early if the test point is further from a volume from the candidate-closest point.
      I'm staying light on the exact details here, since the point of this article is not to explain
      how \(k\)-d trees work.
    </p>
    <p>
      These are very nice data structures, but they suffer from two core issues for our application:
      first, \(k\)-d trees have extremely poor cache locality due to the fact that they jump around
      everywhere during a search. Second, this approach is not at all amenable to SIMD parallelism,
      which typically requires some amount of branchlessness. How do we make something which is
      similarly performant without the same limitations?
    </p>
    <h2>Being stupid faster</h2>
    <p>
      We can start by noticing a neat quirk of the first pass on a \(k\)-d tree: the first downward
      pass can be done completely branchlessly and in a very cache-friendly way. To do so, we'll
      need to bring out a special data layout for trees, called an Eytzinger layout. This
      <a href="https://algorithmica.org/en/eytzinger">Algorithmica article</a> gives a beautiful
      explanation of it, but I'll try my own hand at an explanation as well.
    </p>
    <figure>
      <img src="/assets/img/afftree/eytzinger.svg" class="night-invert" />
      <figcaption>An illustration of the Eytzinger layout on a tree with 7 elements.</figcaption>
    </figure>
    <p>
      In an Eytzinger layout, we implicitly describe the location of each branch in the tree by its
      location in a buffer. We store all the tests in some array (let's call it
      <code>tests</code> for convenience), and for some branch-point at index \(i\), the left child
      will be at position \(2i + 1\), while the right child will be at position \(2i + 2\). If we
      assume that the number of points in the tree is a power of 2, and that the tree is perfectly
      balanced, we can create an extremely efficient method for the first pass through the tree.
    </p>
    <pre class="rust"><code>struct ForwardTree {
    /// contains 2^p - 1 tests
    tests: Box&lt;[f32]&gt;,
    /// contains 2^p points
    points: Box&lt;[[f32; 3]]&gt;,
}

/// Return the index representing
/// the cell in the tree containing `point`.
fn first_pass(tests: &[f32], point: &[f32; 3]) -&gt; usize {
    let mut k = 0;
    let mut i = 0;
    while i &lt; tests.len() {
        i = 2 * i + 1 + usize::from(tests[i] &lt; point[k]);
        k = (k + 1) % 3;
    }

    i - tests.len()
}</code></pre>
    <p>
      This first pass computes a <code>usize</code> identifying which point in
      <code>points</code> is closest to <code>point</code>. Approximation isn't really good enough
      for collision checking, but we'll find some other tricks for that later. For now, we'll notice
      that it's pretty easy to render this code as a parallel implementation using the nightly
      <code>portable_simd</code> feature for Rust.
    </p>
    <pre class="rust"><code>use std::simd::{prelude::*, LaneCount, Simd, SupportedLaneCount};

fn first_pass_simd&lt;const L: usize&gt;(
    tests: &[f32],
    points: &[Simd&lt;f32, L&gt;; 3],
) -&gt; Simd&lt;usize, L&gt;
where
    LaneCount&lt;L&gt;: SupportedLaneCount,
{
    let mut k = 0;
    let mut i = Simd::splat(0);
    let nlog2 = tests.len().trailing_ones();
    for _ in 0..nlog2 {
        let tests = Simd::gather_or_default(tests, i);
        let cmp = points[k].simd_ge(tests).to_int().cast();
        let one = Simd::splat(1);
        i = (i << one) + one + (cmp & one);
        k = (k + 1) % 3;
    }

    i - Simd::splat(tests.len())
}</code></pre>
    <p>
      The above code does the exact same thing as <code>first_pass</code>, but this time in
      parallel.
    </p>
    <p>
      Once we've extracted the identifier for our approximate-nearest-neighbor, we can do a quick
      test for whether it's in collision by computing the distance to the center of the query
      sphere.
    </p>
    <pre class="rust"><code>/// If this returns `true`, a sphere centered at `point`
/// with radius-squared `rsq` collides with a point in `t`.
/// May erroneously return `false`.
fn forward_coll(t: &ForwardTree, point: &[f32; 3], rsq: f32) -&gt; bool {
    let id = first_pass(&t.tests, point);
    point
        .iter()
        .zip(t.points[id])
        .map(|(&x, y)| (x - y).powi(2))
        .sum::&lt;f32&gt;()
        &lt;= rsq
}</code></pre>
    <p>
      Of course, we can also do our collision checking in a SIMD parallel manner; however, the
      resulting code would be rather verbose and not very interesting, since we'll need to throw
      that code away shortly. I'll skip ahead to the good part, which is the performance results.
    </p>
    <p>
      At these scales, a \(k\)-d tree is the best competitor. Fortunately,
      <code><a href="https://github.com/sdd/kiddo">kiddo</a></code
      >, one of the fastest \(k\)-d tree implementations out there, is easy to install via Cargo.
      I'll be using that as a rough baseline for pointcloud-collision-checking. I found that the
      fastest results came from using <code>within_unsorted</code> on an
      <code>ImmutableKdTree</code>, so I'm using that as my baseline.
    </p>
    <figure>
      <img
        src="/assets/img/afftree/forward_vs_kdt_query.svg"
        alt="A 2D line plot titled 'Query performance of collision-checking structures.' 
      The x-axis is labeled as 'Number of points in cloud,' ranging from 0 to 60000, and the y-axis is labeled as 'Collision check time (ns)'. 
      There are three lines: 'k-d tree (kiddo)' in blue, 'forward tree, sequential' in green, and 'forward tree, SIMD' in green. 
      All the lines grow roughly logarithmically. The blue line starts at around 60 ns, then grows to 250 ns. 
      The orange line starts at around 20 ns, then grows to 60 ns. 
      The green line starts at around 10 ns then grows to 20 ns."
        class="night-invert"
      />
    </figure>
    <p>
      We see that this single-pass approach blows a normal \(k\)-d tree out of the water, yielding
      enormous speedups in query time from hundreds of nanoseconds to only about 10 ns. However,
      this comparison isn't really fair: <code>kiddo</code> is giving us an exact answer to whether
      we're in collision, while our forward tree is only returning an approximate answer.
    </p>
    <p>
      Not only that, our approximate answer isn't even all that good. To test this, I collected a
      real pointcloud and measured the distribution of position error when selecting nearest
      neighbors.
    </p>
    <figure><img src="/assets/img/afftree/forward_error_cdf.svg" class="night-invert" /></figure>
    <p>
      Looking from the cumulative distribution function above, we see that roughly 25% of points
      have an error of over 10 cm. In the world of collision checking, that's enormous - any padding
      conservative enough to make this forward tree useful would make it impossible for a robot to
      find a plan.
    </p>
    <h2>Missing the forest for the trees</h2>
    <p>
      My first idea for fixing this error issue was very simple: if one tree was only right some of
      the time, we could get the results from multiple trees and (hopefully) improve our accuracy.
    </p>
    <p>
      This is not a new idea, per se: random forests are pretty well known in the ML community. The
      core concept is this: we make \(T\) different trees. Each tree is randomly different somehow,
      yielding typically incorrect errors. We can then take the best result from each tree for a
      (hopefully) dramatic improvement in result quality.
    </p>
    <pre class="rust"><code>struct RandomTree {
    tests: Box&lt;[f32]&gt;,
    points: Box&lt;[[f32; 3]]&gt;,
    seed: u32,
}</code></pre>
    <p>
      For the sake of branchless parallelism, we'll randomize each tree according to a pseudo-random
      number generator. Then, when we search through the tree, we determine the next axis to branch
      on based on the outcome from the RNG.
    </p>
    <pre class="rust"><code>/// A simple PRNG.
fn xorshift32(x: &mut u32) -&gt; u32 {
    *x ^= *x &lt;&lt; 13;
    *x ^= *x &gt;&gt; 17;
    *x ^= *x &lt;&lt; 5;
    *x
}

fn first_pass_rand(tests: &[f32], mut x: u32, point: &[f32; 3]) -> usize {
    let mut i = 0;
    while i &lt; tests.len() {
        let k = xorshift32(&mut x) as usize % 3;
        i = 2 * i + 1 + usize::from(tests[i] &lt; point[k]);
    }

    i - tests.len()
}
</code></pre>
    <p>
      An astute reader might note that this implementation branches on the same dimension for each
      depth in each random tree, independent of which subtree we search. This is intentional: it
      makes it easier to write a branchless SIMD implementation of random tree querying. Otherwise,
      we'd need a convoluted sequence of shuffles to get every element in the correct lane, which
      would chew up the performance.
    </p>
    <p>
      Young and full of hope, I tried checking the error distribution of the random forest approach.
      I constructed a point cloud, randomly generated a bunch of query points, and tested those
      points for their distance to their nearest neighbor in the cloud.
    </p>
    <figure><img src="/assets/img/afftree/forest_error.svg" class="night-invert" /></figure>
    <p>
      When testing the error distribution for a forest, the results are less than impressive. We get
      diminishing returns at around 4 trees in the forest, with minimal gains from adding trees past
      that. Even with 10 trees in the first, we're off by 0.16m more than 50% of the time. These
      results are simply not good enough for collision-checking.
    </p>
    <h2>A budget for affording</h2>
    <p>
      Let's briefly take stock of the situation. Using our forward tree, we can quickly classify a
      query point as belonging to a single unit cell. We know that for any fixed cell and radius of
      a test-sphere, there is a finite set of points which are close enough to collide with at least
      one point in the cell. If we're targeting a particular robot, we also know \(r_{max}\), the
      maximum radius of a sphere on the robot. If we trust that we'll never do a collision check for
      a sphere larger than \(r_{max}\), then any query point in a given cell can only ever collide
      with a fixed set of points in the cloud: namely, the set of points whose distance to the cell
      is less than or equal to \(r_{max}\).
    </p>
    <figure>
      <img src="/assets/img/afftree/affordance_min.svg" class="night-invert" />
      <figcaption>
        The cell containing \(d\) affords \(a\), \(c\), and \(e\) at radius \(r\), but not \(b\) or
        \(f\).
      </figcaption>
    </figure>
    <p>
      Let's call those points <em>afforded</em>; that is, for a given cell \(C\) and a radius \(r\),
      \(C\) affords \(p\) if there exists a point \(x \in C\) such that \(\|p - x\| \leq r\).
    </p>
    <p>
      Using our knowledge of \(r_{max}\), we can annotate each leaf of our forward-tree with the
      list of all afforded points. Then, when checking for collision, we can traverse this list of
      afforded points and test for collision against any of them. This allows us to convert our
      approximate-nearest-neighbor guess into a completely accurate range-nearest-neighbors query. I
      currently call the resulting structure an
      <em>collision-affording point tree</em>, or <em>CAPT</em> for short.
    </p>
    <p>
      Now, instead of storing a single point for each leaf of the tree, we'll store a list of points
      which might be in collision, called an <em>affordance set</em>.
    </p>
    <pre class="rust"><code>struct Capt {
    tests: Box&lt;[f32]>,
    afforded: Box&lt;[Box&lt;[[f32; 3]]&gt;]&gt;,
}</code></pre>
    <p>
      However, this data layout isn't quite optimal. We've broken up our possibly-colliding points
      into a bunch of different allocations, requiring an extra size parameter on each and
      fragmenting our memory. We can coagulate all the affordance set into one gigantic array, and
      then use another lookup table to get the starting and ending indices relevant to one point.
    </p>
    <p>
      Additionally, to make SIMD parallelism easier, we can use a struct-of-arrays layout for each
      point in <code>afforded</code>, which means that we split out each dimension of every point,
      and store them in separate buffers.
    </p>
    <pre class="rust"><code>struct Capt {
    /// contains n - 1 elements
    tests: Box&lt;[f32]&gt;,
    /// contains n + 1 elements
    starts: Box&lt;[usize]&gt;,
    /// each buffer contains aff_starts[n] elements
    afforded: [Box&lt;[f32]&gt;; 3],
}</code></pre>
    Once we have a cell index <code>id</code> from <code>first_pass</code>,
    <code>afforded[starts[id]..starts[id + 1]]</code> will contain all the afforded points for the
    cell.
  </body>
  <pre class="rust"><code>fn capt_collides(t: &Capt, point: &[f32; 3], rsq: f32) -&gt; bool {
    let id = first_pass(&t.tests, point);
    (t.starts[id]..t.starts[id + 1]).any(|i| {
        t.afforded
            .iter()
            .zip(point)
            .map(|(a, &b)| (a[i] - b).powi(2))
            .sum::&lt;f32&gt;()
            &lt;= rsq
    })
}</code></pre>
  <p>
    If we tried to parallelize collision-checking between our query spheres and afforded points like
    we did in <code>first_pass</code>, we wouldn't actually see much perfomance benefit. I know this
    because that's what I had originally tried, and it was hardly faster than the sequential
    implementation. The heart of the problem is that gather instructions are comically slow on
    nearly all processors, so the CPU spends far more time waiting for memory to arrive than it does
    on churning through computations.
  </p>
  <p>
    To fix this, we need to have a way to test for collision without touching a large about of
    memory at the same time. The simplest fix is the best: instead of parallelizing across queries,
    we parallelize across afforded points for one query. We iterate sequentially through the query
    spheres, but in parallel, we check whether <code>L</code> different afforded points collide with
    the same sphere. The upside of this is that the data for these points are stored contiguously,
    so we waste no time waiting on gathers.
  </p>
  <pre class="rust"><code>fn capt_collides_simd&lt;const L: usize&gt;(
    t: &Capt,
    points: &[Simd&lt;f32, L&gt;; 3],
    radii: Simd&lt;f32, L&gt;,
) -&gt; bool
where
    LaneCount&lt;L&gt;: SupportedLaneCount,
{
    let ids = first_pass_simd(&t.tests, points);

    let start = Simd::gather_or_default(&t.starts, ids);
    let end = Simd::gather_or_default(&t.starts, ids + Simd::splat(1));

    for l in 0..L {
        let pt = [0, 1, 2].map(|k| Simd::splat(points[k][l]));
        let rsq = Simd::splat(radii[l].powi(2));
        for s in (start[l]..end[l]).step_by(L) {
            let mut distsq = Simd::splat(0.0);
            for (pt_k, aff_k) in pt.iter().zip(&t.afforded) {
                // assume `affordances[k]` is sufficently long
                // for simplicity
                let diff = pt_k - Simd::from_slice(&aff_k[s..]);
                distsq += diff * diff;
            }
            if distsq.simd_le(rsq).any() {
                return true;
            }
        }
    }

    false
}</code></pre>
  <h2>Squeezing out some juice</h2>
  <p>
    The performance of this "default" tree is pretty good, but there's one place where it suffers a
    lot: non-colliding queries. If a query sphere doesn't collide with any afforded point, we have
    to check every single afforded point. Some cells could afford hundreds of points, which would
    yield extremely poor runtimes. We need some sort of fast-path rejection for queries which are
    certainly not in collision.
  </p>
  <h3>Getting in order</h3>
  <p>
    I first observed that many query spheres had much smaller radii than the maximum afforded radius
    of the tree. This means that many of the afforded points for each cell would be further from the
    cell than the query radius, meaning that they could never collide with a query sphere of that
    radius.
  </p>
  <figure>
    <img src="/assets/img/afftree/sort_affordance.svg" class="night-invert" />
    <figcaption>
      The cell affords 3 points at \(r_\text{max}\) that it doesn't afford at \(r_q\), so a query
      sphere of radius \(r_q\) wouldn't need to check collision against those points.
    </figcaption>
  </figure>
  <p>
    The first idea we had for this was to sort all the points in each affordance set in descending
    order of distance to the cell. That way, searches with small query radi would be able to
    terminate earlier: as soon as the collision-check found a point further from the cell than the
    query radius, the search could terminate immediately.
  </p>
  <p>
    This was good for query performance, but came at a significant cost in tree construction time.
    I'll explain the details of construction later in this post, but for now, know that this measure
    put construction times into the worst-case regime of \(O(n^2 \log n)\) for trees containing
    \(n\) points. This is far too much time when \(n\) is measured in thousands; in some of my tests
    it took 30 seconds to construct the tree on large point clouds. In the end, I had to nix this
    feature for performance.
  </p>
  <h3>Shrinking down</h3>
  <figure>
    <img src="/assets/img/afftree/rmin.svg" class="night-invert" />
    <figcaption>
      The sphere centered on the representative point with radius \(r_\text{min}\) contains the
      entire cell, so all query spheres centered in this cell are in collision.
    </figcaption>
  </figure>
  <p>
    While experimenting, I found that a very small minority of cells had extremely large affordance
    sets. These cells were typically very small, and in the middle of a big cluster of points.
    Often, because the cells were so small, every single query sphere inside the cell would collide
    with the representative point of the cell.
  </p>
  <p>
    I decided to take advantage of this to reduce the peak affordance size. We already accept that
    we know \(r_\text{max}\), so why not also provide a minimum radius \(r_\text{min}\)? If a sphere
    of radius \(r_\text{min}\) collides with a point, then any other query sphere with the same
    center should also collide, no matter what.
  </p>
  <h3>Bounding my boxes</h3>
  <figure>
    <img src="/assets/img/afftree/aabb.svg" class="night-invert" />
    <figcaption>
      The axis-aligned bounding box, in green, contains all points afforded by the cell.
    </figcaption>
  </figure>
  <p>
    There's one last notable case where the search spends a lot of time needlessly checking for
    collisions. Cells near the edge of a cluster are often long and skinny, with one tip of the cell
    being very close to the cluster and the other tip extending far out into space. Those long,
    skinny cells often take up the majority of the free space in the environment, meaning most of
    our queries will actually be against a cell which is mostly taken up by free space.
  </p>
  <p>
    We'd like to be able to filter out queries which aren't in collision as fast as possible,
    ideally skipping the lengthy affordance set check. Since often only one part of the cell
    contains afforded points, this opens up a possibility for improvement: what if we just didn't
    check the spheres in the "empty" part of the cell?
  </p>
  <p>
    To do this, we an axis-aligned bounding box (AABB) containing the affordance set for each cell.
    If we're lucky, the AABB will often be much smaller than its cell.
  </p>
  <pre class="rust"><code>struct Capt {
    /// contains n - 1 elements
    tests: Box&lt;[f32]&gt;,
    /// contains n elements
    aabbs: Box&lt;[Aabb]&gt;,
    /// contains n + 1 elements
    starts: Box&lt;[usize]&gt;,
    /// each buffer contains aff_starts[n] elements
    afforded: [Box&lt;[f32]&gt;; 3],
}

#[derive(Clone, Copy)]
struct Aabb {
    lo: [f32; 3],
    hi: [f32; 3],
}
</code></pre>
  <p>
    Then, when querying, we'll determine whether some query sphere intersects the AABB. If it
    doesn't, then we know that the sphere is not in collision, and can quickly avoid checking it.
  </p>
  <pre class="rust"><code>fn intersects(aabb: &Aabb, center: &[f32; 3], rsq: f32) -&gt; bool {
    aabb.lo
        .into_iter()
        .zip(aabb.hi)
        .zip(center)
        .map(|((l, h), x)| |((l, h), x)| (x.clamp(l, h) - x).powi(2))
        .sum::&lt;f32&gt;()
        &lt;= rsq
}

/// Rewritten from the previous version.
fn capt_collides(t: &Capt, point: &[f32; 3], rsq: f32) -&gt; bool {
  let id = first_pass(&t.tests, point);
  intersects(&t.aabbs[id], point, rsq)
      && (t.starts[id]..t.starts[id + 1]).any(|i| {
          t.afforded
              .iter()
              .zip(point)
              .map(|(a, &b)| (a[i] - b).powi(2))
              .sum::&lt;f32&gt;()
              &lt;= rsq
      })
}</code></pre>
  <h2>Under construction</h2>
  <figure>
    <img src="/assets/img/afftree/construct_top.svg" style="width: 50%" />
    <figcaption>
      At the first step of construction, the cell is partitioned by its median plane on one axis.
    </figcaption>
  </figure>
  <figure>
    <div style="display: flex">
      <!-- cursed hack to make this lay out like I want it to -->
      <img src="/assets/img/afftree/construct_left.svg" />
      <div style="min-width: 50px"></div>
      <img src="/assets/img/afftree/construct_right.svg" />
    </div>
    <figcaption>
      This produces two new cells, each with half as many points. The affordance set is filtered
      down and then expanded to include points from the opposite side of the partition.
    </figcaption>
  </figure>
  <p>
    After all this, I still haven't explained how these trees are constructed. Efficiently
    constructing a CAPT is nontrivial, since the brute-force approach to affordance set construction
    is a total non-starter. Luckily, the construction procedure is much like that of a normal
    \(k\)-d tree.
  </p>
  <p>
    We start out given some list of \(n\) points \(P\), in our point cloud. Since our
    Eytzinger-layout-based search procedure requires \(n\) to be a power of two, we compute \(n'\),
    which is the next power of two after \(n\), and then pad \(P\) to length \(n'\) with points at
    \(\left<\infty,\infty,\infty\right>\) to produce \(P'\).
  </p>
  <p>
    Next, we recursively partition the tree, maintaining a candidate affordance set \(z\),
    initialized as an empty set; and a candidate volume \(c\), intialized to the axis-aligned
    bounding box containing all of \(\mathbb{R}^3\). Recursively, we partition \(P'\) by the
    following steps:
  </p>
  <ol>
    <li>Compute the median plane for the current cell.</li>
    <li>
      Split the cell by the median plane into two smaller cells, \(c_1\) and \(c_2\). Split the
      points in the cell into two subsets: those below the median plane and those above the median
      plane; call them \(P_1\) and \(P_2\).
    </li>
    <li>
      Construct new affordance sets \(z_1\) and \(z_2\), such that \(z_1 = z \cup P_2\) and \(z_2 =
      z \cup P_1\).
    </li>
    <li>
      Filter out all points in \(z_1\) which are not afforded by \(c_1\) at radius \(r_\text{max}\).
      Do the same for \(z_2\) and \(c_1\).
    </li>
    <li>
      Recursively repeat this process for both partitioned cells until each cell contains only one
      point.
    </li>
  </ol>
  <p>
    I'm intentionally avoiding code in my description here because the code required to construct
    the tree is quite verbose. I've made a stripped-down version in the spoiler block below for
    completeness, though.
  </p>
  <details>
    <summary>*deep breath*</summary>
    <p>First, a helper function for determining whether a sphere contains all of a cell:</p>
    <pre class="rust"><code>fn sphere_contains(center: &[f32; 3], rsq: f32, vol: &Aabb) -&gt; bool {
    vol.lo
        .into_iter()
        .zip(vol.hi)
        .zip(center)
        .map(|((l, h), c)| if c - l &lt; h - c { h - c } else { c - l }.powi(2))
        .sum::&lt;f32&gt;()
        &lt;= rsq
}</code></pre>

    <p>
      We start by padding the points to a power of two, then immediately call out to a helper
      function to populate all the buffers.
    </p>
    <pre class="rust"><code>fn capt_new(points: &[[f32; 3]], r_range: (f32, f32)) -&gt; Capt {
    let n2 = points.len().next_power_of_two();
    let mut points2: Vec&lt;_&gt; = vec![[f32::INFINITY; 3]; n2];
    points2[..points.len()].copy_from_slice(points);
    let mut tests = vec![f32::NAN; n2 - 1].into_boxed_slice();
    let mut afforded = [Vec::new(), Vec::new(), Vec::new()];
    let mut starts = vec![0];
    let mut aabbs = Vec::new();

    capt_new_help(
        &mut points2,
        &mut tests,
        &mut aabbs,
        &mut afforded,
        &mut starts,
        0,
        0,
        r_range,
        Vec::new(),
        Aabb {
            lo: [f32::NEG_INFINITY; 3],
            hi: [f32::INFINITY; 3],
        },
    );

    Capt {
        tests,
        aabbs: aabbs.into_boxed_slice(),
        starts: starts.into_boxed_slice(),
        afforded: afforded.map(Vec::into_boxed_slice),
    }
}</code></pre>
    <p>
      Next, we write the main recursive helper function for splitting up cells and populating the
      affordance sets. If this looks convoluted, remember that the version used in the final code
      was even worse.
    </p>
    <pre class="rust"><code>#[allow(clippy::too_many_arguments)]
fn capt_new_help(
    points: &mut [[f32; 3]],
    tests: &mut [f32],
    aabbs: &mut Vec&lt;Aabb&gt;,
    afforded: &mut [Vec&lt;f32&gt;; 3],
    starts: &mut Vec&lt;usize&gt;,
    k: usize,
    i: usize,
    r_range: (f32, f32),
    in_range: Vec&lt;[f32; 3]&gt;,
    cell: Aabb,
) {
    // Base case: only one point in the cell means this is a leaf
    if let [rep] = *points {
        // AABB of all afforded points
        let mut aabb = Aabb { lo: rep, hi: rep };

        // Exclude padded infinites from affordance sets
        if rep[0].is_finite() {
            // Representative point comes first
            (0..3).for_each(|k| afforded[k].push(rep[k]));
            // Don't include other points if the cell is small enough
            if !sphere_contains(&rep, r_range.0.powi(2), &cell) {
                for p in in_range {
                    for k in 0..3 {
                        // Expand AABB to contain afforded points
                        if p[k] &lt; aabb.lo[k] {
                            aabb.lo[k] = p[k];
                        } else if aabb.hi[k] &lt; p[k] {
                            aabb.hi[k] = p[k];
                        }
                        afforded[k].push(p[k]);
                    }
                }
            }
        }
        // Update starts to match this region of afforded
        starts.push(afforded[0].len());
        aabbs.push(aabb);
        return;
    }

    // Recursive case: splitting a cell

    // Compute the median plane of the cell
    let (lh, med_hi, _) = points
        .select_nth_unstable_by(points.len() / 2, |a, b| {
            a[k].partial_cmp(&b[k]).unwrap()
        });
    let med_lo = lh
        .iter()
        .max_by(|a, b| a[k].partial_cmp(&b[k]).unwrap())
        .unwrap();
    let test = (med_lo[k] + med_hi[k]) / 2.0;
    tests[i] = test;

    // Split the volumes
    let mut lo_range = in_range.clone();
    let mut hi_range = in_range;

    let mut lo_vol = cell;
    lo_vol.hi[k] = test;
    let mut hi_vol = cell;
    hi_vol.lo[k] = test;

    // Compute the new afforded sets
    lo_range.retain(|p| intersects(&lo_vol, p, r_range.1.powi(2)));
    hi_range.retain(|p| intersects(&hi_vol, p, r_range.1.powi(2)));

    let (lhs, rhs) = points.split_at_mut(points.len() / 2);
    lo_range.extend(rhs.iter().filter(|p| p[k] &lt;= test + r_range.1));
    hi_range.extend(lhs.iter().filter(|p| p[k] &gt;= test - r_range.1));

    // Recur for each half of the split
    capt_new_help(
        lhs,
        tests,
        aabbs,
        afforded,
        starts,
        (k + 1) % 3,
        2 * i + 1,
        r_range,
        lo_range,
        lo_vol,
    );

    capt_new_help(
        rhs,
        tests,
        aabbs,
        afforded,
        starts,
        (k + 1) % 3,
        2 * i + 2,
        r_range,
        hi_range,
        hi_vol,
    );
}</code></pre>
  </details>
  <figure>
    <img src="/assets/img/afftree/construct_time.svg" />
  </figure>
  <p>
    Unfortunately, even with some extra engineering work, our construction times for the tree still
    sucked. I even tried transforming the recursive construction procedure into a stack-based
    iterative one. At the end of the day, the core problem is simply algorithmic: if the average
    affordance-set size is \(a\), and there are \(n\) points, construction takes roughly \(O(k n
    a)\) time for sufficiently large \(a\). In most cases, \(a\) grows with \(n\), so it could
    perform as slowly as \(O(kn^2)\) in some clouds. For a cloud with a few hundred thousand points,
    that's completely untenable.
  </p>
  <h2>Filter feeders</h2>
  <p>
    The most natural soluution to our construction time problem is to reduce the size of our point
    clouds. There are many ways to do this, and the simplest way is to just uniformly randomly
    sample points from the cloud until we have the desired quantity. However, most methods provide
    few guarantees about the quality of the sampled cloud. Ideally, we want to downsample the cloud
    to reduce its density as much as possible; however, we can't downsample so much that we
    hallucinate a gap in the cloud and produce an invalid plan. Accordiingly, we'll need a more
    intelligent filtering scheme.
  </p>
  <p>
    While we were thinking about filtering point clouds, we were also thinking about efficient
    construction algorithms for the tree. One idea we had played with was implicit representation
    for afforded sets. The hope was that we could store less data while constructing the tree and
    filter out affordance sets in \(O(1)\) time. One such approach used segments of a space-filling
    curve to represent sets of points, which would hopefully have allowed us to slice up affordance
    sets much more efficiently.
  </p>
  <p>
    Unfortunately for us, that approach never worked out, and so we were stuck with our bad
    construction times. However, we still had the idea of space-filling curves on our mind when we
    were thinking about filtering the point cloud. How could we use a space filling curve to
    fiileter out point clouds more efficiently?
  </p>
  <p>
    I'll start with a simple example. Suppose we have a list of points in one-dimensional space;
    that is, a list of real numbers, and we want to filter it to reduce its density, but still
    preserve the areas where points are in collision. In particular, we might want to make sure that
    if some point \(p\) is removed, there exists another point \(p^*\) which was
    <em>not</em> removed, such that \(\|p^* - p\|\) is less than some radius \(r_\text{filter}\).
  </p>
  <h2>Into the C++ mines</h2>
  <p>
    I hate C++. This isn't a place for unhinged ranting about programming languages, but let it be
    known that I do not write C++ willingly or lightly. However, the vector-accelerated motion
    planner that I was developing for was written in C++, and there's no shot of it getting
    rewritten in the near future. We all have better things to do. Instead, I got to reimplement all
    the Rust prototype code in C++.
  </p>
  <p>
    On the whole, it wasn't as bad as it could have been, but a small part of me dies inside every
    time I have to read a template substantiation error message. My Rust implementation (not the
    simplified version in this blog post) was polymorphic over data types and distance metrics, but
    I only had to implement the C++ version for <code>float</code>s, <code>_mm256i</code>s, and the
    \(L_2\) metric.
  </p>
  <h2>The final scramble</h2>
  <h2>Victory laps</h2>
  <h2>Auslaut</h2>
</html>
