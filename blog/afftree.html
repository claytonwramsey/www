<!DOCTYPE html>

<!-- 
  Hi! Thanks for checking out this website. 
  I made it myself! 
  This website was made by hand. 
  I intentionally haven't minified anything so you can see how it all fits together.
-->

<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="author" content="Clayton Ramsey" />
    <meta name="description" content="TODO" />
    <meta name="keywords" content="robots, Rust, SIMD" />

    <title>Making robots plan faster with SIMD and Rust</title>

    <link rel="stylesheet" type="text/css" href="/assets/main.css" />
    <link rel="stylesheet" href="/assets/hljs.css" />
    <link rel="icon" href="/assets/img/favicon.ico" />

    <script src="/assets/js/highlight.min.js"></script>
    <script id="MathJax-script" async src="/assets/js/mathjax/tex-mml-chtml.js"></script>

    <script>
      hljs.highlightAll();
    </script>
  </head>
  <body>
    <header>
      <nav>
        <a href="/index.html">Home</a>
        <a href="/about.html">About</a>
        <a href="/blog.html">Blog</a>
        <a href="/recipes.html">Recipes</a>
      </nav>
    </header>
    <h1>Making robots plan faster with SIMD and Rust</h1>
    <p>
      I'm now wrapping up my first "real" research project of my my Ph.D., which is both exciting
      and very stressful at the same time. I got to experiment with a lot of really cool things, but
      most of them didn't actually work. I'm writing this blog post as a collection of the story
      behind the paper, where I get to explain all the things I tried that didn't work out, as well
      as to share the untold story of the paper.
    </p>
    <p>
      If you want to skip straight to just reading the final paper, check it our on arXiV
      <strong>INSERT ARXIV LINK!!!!</strong>.
    </p>
    <h2>The problem at hand</h2>
    <p>
      A few months ago, two postdocs in my lab published a
      <a
        href="https://arxiv.org/abs/2309.14545v2?trk=feed_main-feed-card_reshare_feed-article-content"
        >paper</a
      >
      demonstrating dramatic speedups by using SIMD and precompilation for motion planning. However,
      their approach assumed that they had access to a primitive representation of the environment,
      which is rarely the case in reality. In many applications, robots must plan using their
      observed sensor data - namely, pointclouds.
    </p>
    <p>
      In most sampling-based planning algorithms, such as RRT and PRM, collision checking is
      far-and-away the most commonly called (and therefore the most expensive) subroutine. This
      means that we have to develop methods for efficiently checking whether our robot is in
      collision with a pointcloud.
    </p>
    <p>
      We can start by assuming that our robot can be modeled as a set of balls over some distance
      metric. Using the \(L^2\) distance metric, these balls are spheres, which meshes conveniently
      with sphere-hierarchy representations of robot geometry. This lets us neatly reduce the
      problem of collision-checking all kinds of robot geometries into one simple case: checking
      whether a some set of spheres collides with a set of points. In addition to that, we would
      like to be able to do our collision checking in parallel at an instruction level to radically
      improve our performance.
    </p>
    <h2>Review: \(k\)-d trees</h2>
    <p>
      There's a simple solution to our collision-checking problem using a nearest-neighbors data
      structure. Given a set of points \(P\) in the pointcloud, construct a nearest-neighbor data
      structure over \(P\). Then, whenever we have to check whether some sphere with center \(x\)
      and radius \(r\) is in collision, we find the closest point \(p\) in \(P\) to \(x\), and check
      whether the distance from \(x\) to \(p\) is greater than \(r\).
    </p>
    <p>
      The canonical approach to computing nearest-neighbors is a \(k\)-d tree - a class of space
      partitioning tree. There are many formulations, but I'll use a median-partitioning tree in
      this case.
    </p>
    <p>
      At each branch of a \(k\)-d tree, we split the the space into two sub-volumes, each containing
      the same number of points, based on the median value along one dimension. For instance, if we
      wanted to split the points \(\{(2, 3), (4, 4)\}\) along the first dimension, we'd choose a
      split value of 3, and if we were splitting along the second dimension, we'd choose a split of
      3.5. For efficiency, we'll have our tree split first on dimension 0 (\(x\)), then dimension 1
      (\(y\)), and so on, until looping back around to dimension 0.
    </p>
    <figure>
      <img src="/assets/img/afftree/kdt_partition.svg" class="night-invert" />
      <figcaption>The partitioned cells of a \(k\)-d tree.</figcaption>
    </figure>
    <p>
      When querying the nearest neighbor, we first do a quick binary search of the tree to find a
      candidate closest point. Next, we perform a branch-and-bound search of every other subtree,
      escaping early if the test point is further from a volume from the candidate-closest point.
      I'm staying light on the exact details here, since the point of this article is not to explain
      how \(k\)-d trees work.
    </p>
    <p>
      These are very nice data structures, but they suffer from two core issues for our application:
      first, \(k\)-d trees have extremely poor cache locality due to the fact that they jump around
      everywhere during a search. Second, this approach is not at all amenable to SIMD parallelism,
      which typically requires some amount of branchlessness. How do we make something which is
      similarly performant without the same limitations?
    </p>
    <h2>Being stupid faster</h2>
    <p>
      We can start by noticing a neat quirk of the first pass on a \(k\)-d tree: the first downward
      pass can be done completely branchlessly and in a very cache-friendly way. To do so, we'll
      need to bring out a special data layout for trees, called an Eytzinger layout. This
      <a href="https://algorithmica.org/en/eytzinger">Algorithmica article</a> gives a beautiful
      explanation of it, but I'll try my own hand at an explanation as well.
    </p>
    <figure>
      <img src="/assets/img/afftree/eytzinger.svg" class="night-invert" />
      <figcaption>An illustration of the Eytzinger layout on a tree with 7 elements.</figcaption>
    </figure>
    <p>
      In an Eytzinger layout, we implicitly describe the location of each branch in the tree by its
      location in a buffer. We store all the tests in some array (let's call it
      <code>tests</code> for convenience), and for some branch-point at index \(i\), the left child
      will be at position \(2i + 1\), while the right child will be at position \(2i + 2\). If we
      assume that the number of points in the tree is a power of 2, and that the tree is perfectly
      balanced, we can create an extremely efficient method for the first pass through the tree.
    </p>
    <pre class="rust"><code>struct ForwardTree {
    /// contains 2^p - 1 tests
    tests: Box&lt;[f32]&gt;,
    /// contains 2^p points
    points: Box&lt;[[f32; 3]]&gt;,
}

/// Return the index representing
/// the cell in the tree containing `point`.
fn first_pass(tests: &[f32], point: &[f32; 3]) -&gt; usize {
    let mut k = 0;
    let mut i = 0;
    while i &lt; tests.len() {
        i = 2 * i + 1 + usize::from(tests[i] &lt; point[k]);
        k = (k + 1) % 3;
    }

    i - tests.len()
}</code></pre>
    <p>
      This first pass computes a <code>usize</code> identifying which point in
      <code>points</code> is closest to <code>point</code>. Approximation isn't really good enough
      for collision checking, but we'll find some other tricks for that later. For now, we'll notice
      that it's pretty easy to render this code as a parallel implementation using the nightly
      <code>portable_simd</code> feature for Rust.
    </p>
    <pre class="rust"><code>use std::simd::{prelude::*, LaneCount, Simd, SupportedLaneCount};

fn first_pass_simd&lt;const L: usize&gt;(
    tests: &[f32],
    points: &[Simd&lt;f32, L&gt;; 3],
) -&gt; Simd&lt;usize, L&gt;
where
    LaneCount&lt;L&gt;: SupportedLaneCount,
{
    let mut k = 0;
    let mut i = Simd::splat(0);
    let nlog2 = tests.len().trailing_ones();
    for _ in 0..nlog2 {
        let tests = Simd::gather_or_default(tests, i);
        let cmp = points[k].simd_ge(tests).to_int().cast();
        let one = Simd::splat(1);
        i = (i << one) + one + (cmp & one);
        k = (k + 1) % 3;
    }

    i - Simd::splat(tests.len())
}</code></pre>
    <p>
      The above code does the exact same thing as <code>first_pass</code>, but this time in
      parallel.
    </p>
    <p>
      Once we've extracted the identifier for our approximate-nearest-neighbor, we can do a quick
      test for whether it's in collision by computing the distance to the center of the query
      sphere.
    </p>
    <pre class="rust"><code>/// If this returns `true`, a sphere centered at `point`
/// with radius `r` collides with a point in `t`.
/// May erroneously return `false`.
fn forward_coll(t: &ForwardTree, point: &[f32; 3], radius: f32) -&gt; bool {
    let id = first_pass(&t.tests, point);
    point
        .iter()
        .zip(t.points[id])
        .map(|(&x, y)| (x - y).powi(2))
        .sum::&lt;f32&gt;()
        &lt;= radius
}</code></pre>
    <p>
      Of course, we can also do our collision checking in a SIMD parallel manner; however, the
      resulting code would be rather verbose and not very interesting, since we'll need to throw
      that code away shortly. I'll skip ahead to the good part, which is the performance results.
    </p>
    <p>
      At these scales, a \(k\)-d tree is the best competitor. Fortunately,
      <code><a href="https://github.com/sdd/kiddo">kiddo</a></code
      >, one of the fastest \(k\)-d tree implementations out there, is easy to install via Cargo.
      I'll be using that as a rough baseline for pointcloud-collision-checking. I found that the
      fastest results came from using <code>within_unsorted</code> on an
      <code>ImmutableKdTree</code>, so I'm using that as my baseline.
    </p>
    <figure>
      <img
        src="/assets/img/afftree/forward_vs_kdt_query.svg"
        alt="A 2D line plot titled 'Query performance of collision-checking structures.' 
      The x-axis is labeled as 'Number of points in cloud,' ranging from 0 to 60000, and the y-axis is labeled as 'Collision check time (ns)'. 
      There are three lines: 'k-d tree (kiddo)' in blue, 'forward tree, sequential' in green, and 'forward tree, SIMD' in green. 
      All the lines grow roughly logarithmically. The blue line starts at around 60 ns, then grows to 250 ns. 
      The orange line starts at around 20 ns, then grows to 60 ns. 
      The green line starts at around 10 ns then grows to 20 ns."
        class="night-invert"
      />
    </figure>
    <p>
      We see that this single-pass approach blows a normal \(k\)-d tree out of the water, yielding
      enormous speedups in query time from hundreds of nanoseconds to only about 10 ns. However,
      this comparison isn't really fair: <code>kiddo</code> is giving us an exact answer to whether
      we're in collision, while our forward tree is only returning an approximate answer.
    </p>
    <p>
      Not only that, our approximate answer isn't even all that good. To test this, I collected a
      real pointcloud and measured the distribution of position error when selecting nearest
      neighbors.
    </p>
    <figure><img src="/assets/img/afftree/forward_error_cdf.svg" class="night-invert" /></figure>
    <p>
      Looking from the cumulative distribution function above, we see that roughly 25% of points
      have an error of over 10 cm. In the world of collision checking, that's enormous - any padding
      conservative enough to make this forward tree useful would make it impossible for a robot to
      find a plan.
    </p>
    <h2>Missing the forest for the trees</h2>
    <p>
      My first idea for fixing this error issue was very simple: if one tree was only right some of
      the time, we could get the results from multiple trees and (hopefully) improve our accuracy.
    </p>
    <p>
      This is not a new idea, per se: random forests are pretty well known in the ML community. The
      core concept is this: we make \(T\) different trees. Each tree is randomly different somehow,
      yielding typically incorrect errors. We can then take the best result from each tree for a
      (hopefully) dramatic improvement in result quality.
    </p>
    <pre class="rust"><code>struct RandomTree {
    tests: Box&lt;[f32]&gt;,
    points: Box&lt;[[f32; 3]]&gt;,
    seed: u32,
}

struct RandomForest(Box&lt;[RandomTree]&gt;);</code></pre>
    <p>
      For the sake of branchless parallelism, we'll randomize each tree according to a pseudo-random
      number generator. Then, when we search through the tree, we determine the next axis to branch
      on based on the outcome from the RNG.
    </p>
    <pre class="rust"><code>/// A simple PRNG.
fn xorshift32(x: &mut u32) -&gt; u32 {
    *x ^= *x &lt;&lt; 13;
    *x ^= *x &gt;&gt; 17;
    *x ^= *x &lt;&lt; 5;
    *x
}

fn first_pass_rand(tests: &[f32], mut x: u32, point: &[f32; 3]) -> usize {
    let mut i = 0;
    while i &lt; tests.len() {
        let k = xorshift32(&mut x) as usize % 3;
        i = 2 * i + 1 + usize::from(tests[i] &lt; point[k]);
    }

    i - tests.len()
}
</code></pre>
    <p>
      An astute reader might note that this implementation branches on the same dimension for each
      depth in each random tree, independent of which subtree we search. This is intentional: it
      makes it easier to write a branchless SIMD implementation of random tree querying. Otherwise,
      we'd need a convoluted sequence of shuffles to get every element in the correct lane, which
      would chew up the performance.
    </p>
    <p>
      Young and full of hope, I tried checking the error distribution of the random forest approach.
      I constructed a point cloud, randomly generated a bunch of query points, and tested those
      points for their distance to their nearest neighbor in the cloud.
    </p>
    <figure><img src="/assets/img/afftree/forest_error.svg" class="night-invert" /></figure>
    <p>
      When testing the error distribution for a forest, the results are less than impressive. We get
      diminishing returns at around 4 trees in the forest, with minimal gains from adding trees past
      that. Even with 10 trees in the first, we're off by 0.16m more than 50% of the time. These
      results are simply not good enough for collision-checking.
    </p>
    <h2>A budget for affording</h2>
    <p>
      Let's briefly take stock of the situation. Using our forward tree, we can quickly classify a
      query point as belonging to a single unit cell. We know that for any fixed cell and radius of
      a test-sphere, there is a finite set of points which are close enough to collide with at least
      one point in the cell. If we're targeting a particular robot, we also know \(r_{max}\), the
      maximum radius of a sphere on the robot. If we trust that we'll never do a collision check for
      a sphere larger than \(r_{max}\), then any query point in a given cell can only ever collide
      with a fixed set of points in the cloud: namely, the set of points whose distance to the cell
      is less than or equal to \(r_{max}\).
    </p>
    <figure>
      <img src="/assets/img/afftree/affordance_min.svg" class="night-invert" />
      <figcaption>
        The cell containing \(d\) affords \(a\), \(c\), and \(e\) at radius \(r\), but not \(b\) or
        \(f\).
      </figcaption>
    </figure>
    <p>
      Let's call those points <em>afforded</em>; that is, for a given cell \(C\) and a radius \(r\),
      \(C\) affords \(p\) if there exists a point \(x \in C\) such that \(\|p - x\| \leq r\).
    </p>
    <p>
      Using our knowledge of \(r_{max}\), we can annotate each leaf of our forward-tree with the
      list of all afforded points. Then, when checking for collision, we can traverse this list of
      afforded points and test for collision against any of them. This allows us to convert our
      approximate-nearest-neighbor guess into a completely accurate range-nearest-neighbors query. I
      currently call the resulting structure an
      <em>collision-affording point tree</em>, or <em>CAPT</em> for short.
    </p>
    <p>
      Now, instead of storing a single point for each leaf of the tree, we'll store a list of points
      which might be in collision, called an <em>affordance set</em>.
    </p>
    <pre class="rust"><code>struct Capt {
    tests: Box&lt;[f32]>,
    afforded: Box&lt;[Box&lt;[[f32; 3]]&gt;]&gt;,
}</code></pre>
    <p>
      However, this data layout isn't quite optimal. We've broken up our possibly-colliding points
      into a bunch of different allocations, requiring an extra size parameter on each and
      fragmenting our memory. We can coagulate all the affordance set into one gigantic array, and
      then use another lookup table to get the starting and ending indices relevant to one point.
    </p>
    <p>
      Additionally, to make SIMD parallelism easier, we can use a struct-of-arrays layout for each
      point in <code>afforded</code>, which means that we split out each dimension of every point,
      and store them in separate buffers.
    </p>
    <pre class="rust"><code>struct Capt {
    /// contains n - 1 elements
    tests: Box&lt;[f32]&gt;,
    /// contains n + 1 elements
    starts: Box&lt;[usize]&gt;,
    /// each buffer contains aff_starts[n] elements
    afforded: [Box&lt;[f32]&gt;; 3],
}</code></pre>
    Once we have a cell index <code>id</code> from <code>first_pass</code>,
    <code>afforded[starts[id]..starts[id + 1]]</code> will contain all the afforded points for the
    cell.
  </body>
  <pre class="rust"><code>fn capt_collides(t: &Capt, point: &[f32; 3], radius: f32) -&gt; bool {
    let id = first_pass(&t.tests, point);
    let rsq = radius * radius;
    (t.starts[id]..t.starts[id] + 1).any(|i| {
        t.afforded
            .iter()
            .zip(point)
            .map(|(a, &b)| (a[i] - b).powi(2))
            .sum::&lt;f32&gt;()
            &lt;= rsq
    })
}</code></pre>
  <p>
    If we tried to parallelize collision-checking between our query spheres and afforded points like
    we did in <code>first_pass</code>, we wouldn't actually see much perfomance benefit. I know this
    because that's what I had originally tried, and it was hardly faster than the sequential
    implementation. The heart of the problem is that gather instructions are comically slow on
    nearly all processors, so the CPU spends far more time waiting for memory to arrive than it does
    on churning through computations.
  </p>
  <p>
    To fix this, we need to have a way to test for collision without touching a large about of
    memory at the same time. The simplest fix is the best: instead of parallelizing across queries,
    we parallelize across afforded points for one query. We iterate sequentially through the query
    spheres, but in parallel, we check whether <code>L</code> different afforded points collide with
    the same sphere. The upside of this is that the data for these points are stored contiguously,
    so we waste no time waiting on gathers.
  </p>
  <pre class="rust"><code>fn capt_collides_simd&lt;const L: usize&gt;(
    t: &Capt,
    points: &[Simd&lt;f32, L&gt;; 3],
    radii: Simd&lt;f32, L&gt;,
) -&gt; bool
where
    LaneCount&lt;L&gt;: SupportedLaneCount,
{
    let ids = first_pass_simd(&t.tests, points);

    let start = Simd::gather_or_default(&t.starts, ids);
    let end = Simd::gather_or_default(&t.starts, ids + Simd::splat(1));

    for l in 0..L {
        let pt = [0, 1, 2].map(|k| Simd::splat(points[k][l]));
        let rsq = Simd::splat(radii[l].powi(2));
        for s in (start[l]..end[l]).step_by(L) {
            let mut distsq = Simd::splat(0.0);
            for (pt_k, aff_k) in pt.iter().zip(&t.afforded) {
                // assume `affordances[k]` is sufficently long
                // for simplicity
                let diff = pt_k - Simd::from_slice(&aff_k[s..]);
                distsq += diff * diff;
            }
            if distsq.simd_le(rsq).any() {
                return true;
            }
        }
    }

    false
}</code></pre>
  <h2>Squeezing out some juice</h2>
  <p>
    The performance of this "default" tree is pretty good, but there's one place where it suffers a
    lot: non-colliding queries. If a query sphere doesn't collide with any afforded point, we have
    to check every single afforded point. Some cells could afford hundreds of points, which would
    yield extremely poor runtimes. We need some sort of fast-path rejection for queries which are
    certainly not in collision.
  </p>
  <h3>Getting in order</h3>
  <p>
    I first observed that many query spheres had much smaller radii than the maximum afforded radius
    of the tree. This means that many of the afforded points for each cell would be further from the
    cell than the query radius, meaning that they could never collide with a query sphere of that
    radius.
  </p>
  <figure>
    <img src="/assets/img/afftree/sort_affordance.svg" class="night-invert" />
    <figcaption>
      The cell affords 3 points at \(r_\text{max}\) that it doesn't afford at \(r_q\), so a query
      sphere of radius \(r_q\) wouldn't need to check collision against those points.
    </figcaption>
  </figure>
  <p>
    The first idea we had for this was to sort all the points in each affordance set in descending
    order of distance to the cell. That way, searches with small query radi would be able to
    terminate earlier: as soon as the collision-check found a point further from the cell than the
    query radius, the search could terminate immediately.
  </p>
  <p>
    This was good for query performance, but came at a significant cost in tree construction time.
    I'll explain the details of construction later in this post, but for now, know that this measure
    put construction times into the worst-case regime of \(O(n^2 \log n)\) for trees containing
    \(n\) points. This is far too much time when \(n\) is measured in thousands; in some of my tests
    it took 30 seconds to construct the tree on large point clouds.
  </p>
  <h3>Shrinking down</h3>
  <figure>
    <img src="/assets/img/afftree/rmin.svg" class="night-invert" />
  </figure>
  <h3>Bounding my boxes</h3>
  <figure>
    <img src="/assets/img/afftree/aabb.svg" class="night-invert" />
  </figure>
  <h2>Under construction</h2>
  <h2>Filter feeders</h2>
  <h2>Into the C++ mines</h2>
  <h2>The final scramble</h2>
  <h2>Victory laps</h2>
  <h2>Auslaut</h2>
</html>
