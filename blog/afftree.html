<!DOCTYPE html>

<!-- 
  Hi! Thanks for checking out this website. 
  I made it myself! 
  This website was made by hand. 
  I intentionally haven't minified anything so you can see how it all fits together.
-->

<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="author" content="Clayton Ramsey" />
    <meta name="description" content="TODO" />
    <meta name="keywords" content="robots, Rust, SIMD" />

    <title>Making robots plan faster with SIMD and Rust</title>

    <link rel="stylesheet" type="text/css" href="/assets/main.css" />
    <link rel="stylesheet" href="/assets/hljs.css" />
    <link rel="icon" href="/assets/img/favicon.ico" />

    <script src="/assets/js/highlight.min.js"></script>
    <script id="MathJax-script" async src="/assets/js/mathjax/tex-mml-chtml.js"></script>

    <script>
      hljs.highlightAll();
    </script>
  </head>
  <body>
    <header>
      <nav>
        <a href="/index.html">Home</a>
        <a href="/about.html">About</a>
        <a href="/blog.html">Blog</a>
        <a href="/recipes.html">Recipes</a>
      </nav>
    </header>
    <h1>Making robots plan faster with SIMD and Rust</h1>
    <p>
      I'm now wrapping up my first "real" research project of my my Ph.D., which is both exciting
      and very stressful at the same time.
    </p>
    <h2>The problem at hand</h2>
    <p>
      A few months ago, two postdocs in my lab published a
      <a
        href="https://arxiv.org/abs/2309.14545v2?trk=feed_main-feed-card_reshare_feed-article-content"
        >paper</a
      >
      demonstrating dramatic speedups by using SIMD and precompilation for motion planning. However,
      their approach assumed that they had access to a primitive representation of the environment,
      which is rarely the case in reality. In many applications, robots must plan using their
      observed sensor data - namely, pointclouds.
    </p>
    <p>
      In most sampling-based planning algorithms, such as RRT and PRM, collision checking is
      far-and-away the most commonly called (and therefore the most expensive) subroutine. This
      means that we have to develop methods for efficiently checking whether our robot is in
      collision with a pointcloud.
    </p>
    <p>
      We can start by assuming that our robot can be modeled as a set of balls over some distance
      metric. Using the \(L^2\) distance metric, these balls are spheres, which meshes conveniently
      with sphere-hierarchy representations of robot geometry. This lets us neatly reduce the
      problem of collision-checking all kinds of robot geometries into one simple case: checking
      whether a some set of spheres collides with a set of points. In addition to that, we would
      like to be able to do our collision checking in parallel at an instruction level to radically
      improve our performance.
    </p>
    <h2>Review: \(k\)-d trees</h2>
    <p>
      There's a simple solution to our collision-checking problem using a nearest-neighbors data
      structure. Given a set of points \(P\) in the pointcloud, construct a nearest-neighbor data
      structure over \(P\). Then, whenever we have to check whether some sphere with center \(x\)
      and radius \(r\) is in collision, we find the closest point \(p\) in \(P\) to \(x\), and check
      whether the distance from \(x\) to \(p\) is greater than \(r\).
    </p>
    <p>
      The canonical approach to computing nearest-neighbors is a \(k\)-d tree - a class of space
      partitioning tree. There are many formulations, but I'll use a median-partitioning tree in
      this case.
    </p>
    <p>
      At each branch of a \(k\)-d tree, we split the the space into two sub-volumes, each containing
      the same number of points, based on the median value along one dimension. For instance, if we
      wanted to split the points \(\{(2, 3), (4, 4)\}\) along the first dimension, we'd choose a
      split value of 3, and if we were splitting along the second dimension, we'd choose a split of
      3.5. For efficiency, we'll have our tree split first on dimension 0 (\(x\)), then dimension 1
      (\(y\)), and so on, until looping back around to dimension 0.
    </p>
    <figure>
      <img src="/assets/img/afftree/kdt_partition.svg" class="night-invert" />
      <figcaption>The partitioned cells of a \(k\)-d tree.</figcaption>
    </figure>
    <p>
      When querying the nearest neighbor, we first do a quick binary search of the tree to find a
      candidate closest point. Next, we perform a branch-and-bound search of every other subtree,
      escaping early if the test point is further from a volume from the candidate-closest point.
      I'm staying light on the exact details here, since the point of this article is not to explain
      how \(k\)-d trees work.
    </p>
    <p>
      These are very nice data structures, but they suffer from two core issues for our application:
      first, \(k\)-d trees have extremely poor cache locality due to the fact that they jump around
      everywhere during a search. Second, this approach is not at all amenable to SIMD parallelism,
      which typically requires some amount of branchlessness. How do we make something which is
      similarly performant without the same limitations?
    </p>
    <h2>Being stupid faster</h2>
    <p>
      We can start by noticing a neat quirk of the first pass on a \(k\)-d tree: the first downward
      pass can be done completely branchlessly and in a very cache-friendly way. To do so, we'll
      need to bring out a special data layout for trees, called an Eytzinger layout. This
      <a href="https://algorithmica.org/en/eytzinger">Algorithmica article</a> gives a beautiful
      explanation of it, but I'll try my own hand at an explanation as well.
    </p>
    <figure>
      <img src="/assets/img/afftree/eytzinger.svg" class="night-invert" />
      <figcaption>An illustration of the Eytzinger layout on a tree with 7 elements.</figcaption>
    </figure>
    <p>
      In an Eytzinger layout, we implicitly describe the location of each branch in the tree by its
      location in a buffer. We store all the tests in some array (let's call it
      <code>tests</code> for convenience), and for some branch-point at index \(i\), the left child
      will be at position \(2i + 1\), while the right child will be at position \(2i + 2\). If we
      assume that the number of points in the tree is a power of 2, and that the tree is perfectly
      balanced, we can create an extremely efficient method for the first pass through the tree.
    </p>
    <pre class="rust"><code>struct ForwardTree&lt;const K: usize> {first_pass(t
    /// contains 2^p - 1 tests
    tests: Box&lt;[f32]>,
    /// contains 2^p points
    points: Box&lt;[[f32; K]]>,
}

/// Return the index representing 
/// the cell in the tree containing `point`.
fn first_pass&lt;const K: usize>(
    tests: &[f32], 
    point: &[f32; K],
) -> usize {
    let mut k = 0;
    let mut i = 0;
    while i &lt; tests.len() {
        i = 2 * i + 1 + usize::from(tests[i] &lt; point[k]);
        k = (k + 1) % K;
    }
    
    i - tests.len()
}</code></pre>
    <p>
      This first pass a <code>usize</code> identifying which point in <code>points</code> is closest
      to <code>point</code>. Approximation isn't really good enough for collision checking, but
      we'll find some other tricks for that later. For now, we'll notice that it's pretty easy to
      render this code as a parallel implementation using the nightly
      <code>portable_simd</code> feature for Rust.
    </p>
    <pre class="rust"><code>use std::simd::{prelude::*, LaneCount, Mask, Simd, SupportedLaneCount};
      
fn first_pass_simd&lt;const K: usize, const L: usize&gt;(
    tests: &[f32],
    points: &[Simd&lt;f32, L&gt;; K],
) -&gt; Simd&lt;isize, L&gt;
where
    LaneCount&lt;L&gt;: SupportedLaneCount,
{
    let mut k = 0;
    let mut i = Simd::splat(0);
    let nlog2 = tests.len().trailing_ones();

    for _ in 0..nlog2 {
        // Gather all tests
        let ptrs = Simd::splat(tests.as_ptr()).wrapping_offset(i);
        let tests: Simd&lt;f32, L&gt; = unsafe { Simd::gather_ptr(ptrs) };

        // Compare points to the tests
        let cmp_results: Mask&lt;isize, L&gt; = points[k].simd_ge(tests).into();

        // Update i and k
        let one = Simd::splat(1);
        i = (i &lt;&lt; one) + one + (cmp_results.to_int() & one);
        k = (k + 1) % K;
    }

    i - Simd::splat(tests.len() as isize)
}</code></pre>
    <p>
      In this case, we use <code>isize</code> instead of <code>usize</code> because it makes it a
      little easier to convert masks and SIMD vectors, but otherwise the above code does the exact
      same thing as <code>first_pass</code>, but this time in parallel.
    </p>
    <p>
      Once we've extracted the identifier for our approximate-nearest-neighbor, we can do a quick
      test for whether it's in collision by computing the distance to the center of the query sphere
    </p>
    <pre class="rust"><code>fn distsq&lt;const K: usize&gt;(a: &[f32; K], b: &[f32; K]) -&gt; f32 {
    a.iter().zip(b).map(|(&x, &y)| (x - y).powi(2)).sum::&lt;f32&gt;()
}

/// If this returns `true`, a sphere centered at `point` 
/// with radius `r` collides with a point in `t`.
/// May erroneously return `false`.
fn forward_collision&lt;const K: usize&gt;(
    t: &ForwardTree&lt;K&gt;,
    point: &[f32; K],
    radius: f32,
) -&gt; bool {
    let id = first_pass(&t.tests, point);
    distsq(point, &t.points[id]) &lt;= radius
}</code></pre>
    <p>
      Of course, we can also do our collision checking in a SIMD parallel manner; however, the
      resulting code would be rather verbose and not very interesting, since we'll need to throw
      that code away shortly. I'll skip ahead to the good part, which is the performance results.
    </p>
    <p>
      At these scales, a \(k\)-d tree is the best competitor. Fortunately,
      <code><a href="https://github.com/sdd/kiddo">kiddo</a></code
      >, one of the fastest \(k\)-d tree implementations out there, is to install via Cargo. I'll be
      using that as a rough baseline for pointcloud-collision-checking. I found that the fastest
      results came from using <code>within_unsorted</code> on an <code>ImmutableKdTree</code>, so
      I'm using that as my baseline.
    </p>
    <figure>
      <img
        src="/assets/img/afftree/forward_vs_kdt_query.svg"
        alt="A 2D line plot titled 'Query performance of collision-checking structures.' 
      The x-axis is labeled as 'Number of points in cloud,' ranging from 0 to 60000, and the y-axis is labeled as 'Collision check time (ns)'. 
      There are three lines: 'k-d tree (kiddo)' in blue, 'forward tree, sequential' in green, and 'forward tree, SIMD' in green. 
      All the lines grow roughly logarithmically. The blue line starts at around 60 ns, then grows to 250 ns. 
      The orange line starts at around 20 ns, then grows to 60 ns. 
      The green line starts at around 10 ns then grows to 20 ns."
        class="night-invert"
      />
    </figure>
    <p>
      We see that this single-pass approach blows a normal \(k\)-d tree out of the water, yielding
      enormous speedups in query time from hundreds of nanoseconds to only about 10 ns. However,
      this comparison isn't really fair: <code>kiddo</code> is giving us an exact answer to whether
      we're in collision, while our forward tree is only returning an approximate answer.
    </p>
    <p>
      Not only that, our approximate answer isn't even all that good. To test this, I collected a
      real pointcloud and measured the distribution of position error when selecting nearest
      neighbors.
    </p>
    <figure><img src="/assets/img/afftree/forward_error_cdf.svg" class="night-invert" /></figure>
    <p>
      Looking from the cumulative distribution function above, we see that roughly 25% of points
      have an error of over 10 cm. In the world of collision checking, that's enormous - any padding
      conservative enough to make this forward tree useful would make it impossible for a robot to
      find a plan.
    </p>
    <h2>A budget for affording</h2>
    <p>
      Let's briefly take stock of the situation. Using our forward tree, we can quickly classify a
      query point as belonging to a single unit cell. We know that for any fixed cell and radius of
      a test-sphere, there is a finite set of points which are close enough to collide with at least
      one point in the cell. If we're targeting a particular robot, we also know \(r_{max}\), the
      maximum radius of a sphere on the robot. If we trust that we'll never do a collision check for
      a sphere larger than \(r_{max}\), then any query point in a given cell can only ever collide
      with a fixed set of points in the cloud: namely, the set of points whose distance to the cell
      is less than or equal to \(r_{max}\).
    </p>
    <figure>
      <img src="/assets/img/afftree/affordance_min.svg" class="night-invert" />
      <figcaption>
        The cell containing \(d\) affords \(a\), \(c\), and \(e\) at radius \(r\), but not \(b\) or
        \(f\).
      </figcaption>
    </figure>
    <p>
      Let's call those points <em>afforded</em>; that is, for a given cell \(C\) and a radius \(r\),
      \(C\) affords \(p\) if there exists a point \(x \in C\) such that \(\|p - x\| \leq r\).
    </p>
    <p>
      Using our knowledge of \(r_{max}\), we can annotate each leaf of our forward-tree with the
      list of all afforded points. Then, when checking for collision, we can traverse this list of
      afforded points and test for collision against any of them. This allows us to convert our
      approximate-nearest-neighbor guess into a completely accurate range-nearest-neighbors query. I
      currently call the resulting structure an
      <em>affordance tree</em>, or <em>afftree</em> for short.
      <strong>TODO: come up with a better name.</strong>
    </p>
    <p>
      Now, instead of storing a single point for each leaf of the tree, we'll store a list of points
      which might be in collision, called an <em>affordance buffer</em>.
    </p>
    <pre class="rust"><code>struct AffTree&lt;const K: usize&gt; {
    tests: Box&lt;[f32]>,
    affordances: Box&lt;[Box&lt;[[f32; K]]&gt;]&gt;,
}</code></pre>
    <p>
      However, this data layout isn't quite optimal. We've broken up our possibly-colliding points
      into a bunch of different allocations, requiring an extra size parameter on each and
      fragmenting our memory. We can coagulate all the affordance buffers into one gigantic array,
      and then use another lookup table to get the starting and ending indices relevant to one
      point.
    </p>
    <pre class="rust"><code>struct AffTree&lt;const K: usize&gt; {
    tests: Box&lt;[f32]&gt;,
    /// contains 2^p + 1 elements
    aff_starts: Box&lt;[usize]&gt;,
    /// contains aff_starts[2^p] elements
    affordances: Box&lt;[[f32; k]]&gt;,
}</code></pre>
    Once we have a cell index <code>id</code> from <code>first_pass</code>,
    <code>affordances[aff_starts[id]..aff_starts[id + 1]]</code> will contain all the afforded
    points for the cell.
  </body>
  <pre class="rust"><code>fn aff_collides&lt;const K: usize&gt;(
    t: &AffTree&lt;K&gt;,
    point: &[f32; K],
    radius: f32,
) -&gt; bool {
    let id = first_pass(&t.tests, point);
    let rsq = radius * radius;
    t.affordances[t.aff_starts[id]..t.aff_starts[id] + 1]
        .iter()
        .any(|p| distsq(p, point) &lt;= rsq)
}</code></pre>
  <p>
    When adapting this code to SIMD, however, this presents a problem. The affordances table is
    <em>ragged</em>, meaning that each buffer in the table is of a varying width. If we naively
    loaded from every buffer in order, we could easily cause a buffer overrun as one lane shot past
    its segment of the affordances table. To fix this, we take a leaf out of the GPU parallelism
    book: we'll branch by masking out some lanes from all operations. During the scan through the
    affordance array, we'll use the mask <code>inbounds</code> on
    <code>gather_select</code> operations to prevent lanes from running out of bounds.
  </p>
  <pre class="rust"><code>fn check_affordances&lt;const K: usize, const L: usize&gt;(
    aff_starts: &[usize],
    affordances: &[[f32; K]],
    points: &[Simd&lt;f32, L&gt;; K],
    radii: Simd&lt;f32, L&gt;,
    ids: Simd&lt;isize, L&gt;,
) -&gt; bool
where
    LaneCount&lt;L&gt;: SupportedLaneCount,
{

    // Collect start and end offsets
    let one = Simd::splat(1);
    let off_ptrs = Simd::splat(aff_starts.as_ptr()).wrapping_offset(ids);
    let start = unsafe { Simd::gather_ptr(off_ptrs) };
    let end = unsafe { Simd::gather_ptr(off_ptrs.wrapping_add(one)) };

    // Initialize pointers into affordance buffer
    let base = Simd::splat(affordances.as_ptr());
    let mut ptrs = base.wrapping_add(start).cast::&lt;f32&gt;();
    let end_ptrs = base.wrapping_add(end).cast::&lt;f32&gt;();
    let mut inbounds = ptrs.simd_gt(end_ptrs);
    let rsqs = radii * radii;
    let inf = Simd::splat(f32::INFINITY);
    // For each point in the affordance buffer...
    while inbounds.any() {
        // Compute the distance from sphere centers to afforded points
        let mut dists = Simd::splat(0.0);
        for points_k in points {
            let vals = unsafe { Simd::gather_select_ptr(ptrs, inbounds, inf) };
            let diffs = points_k - vals;
            dists += diffs * diffs;
            ptrs = ptrs.wrapping_add(one);
        }

        // Test for collision
        if dists.simd_le(rsqs).any() {
            return true;
        }

        // Mask out overruns
        inbounds &= ptrs.simd_lt(end_ptrs);
    }

    false
}

fn aff_collides_simd&lt;const K: usize, const L: usize&gt;(
    t: &AffTree&lt;K&gt;,
    points: &[Simd&lt;f32, L&gt;; K],
    radii: Simd&lt;f32, L&gt;,
) -&gt; bool
where
    LaneCount&lt;L&gt;: SupportedLaneCount,
{
    let ids = first_pass_simd(&t.tests, points);font-size
    check_affordances(&t.aff_starts, &t.affordances, points, radii, ids)
}</code></pre>
  <p>
    In practice, however, this code will still be quite slow. The main problem is that the number of
    afforded points for a cell could be quite large - up to fifty or a hundred. Checking all of
    thise points in a row will take a lot of time no matter what, so we need to find a way to reduce
    the expected number of tests.
  </p>
  <p>
    There are two solutions, each of which dovetail nicely with one another. First, we can sort the
    points in each affordance buffer according to how far they are from the cell, in increasing
    order. The point contained in the cloud would come first, followed by those that are extremely
    close to the surface of the cell. This means that if a sphere is in collision, we will probably
    find the points that it collides with quite quickly.
  </p>
  <p>
    Once those points are sorted, we can observe a neat fact about our queries: we might be querying
    the tree with a radius \(r \ll r_{max}\). In that case, we spend a lot of time checking against
    points which will never collide with the query sphere, since a cell affords far more points at
    radius \(r_max\) than it does at \(r\).
  </p>
  <strong>TODO: figure of affording at \(r\) and \(r_{max}\).</strong>
  <p>
    To amend this, we can amend every point in the affordance buffer with its distance to the cell.
  </p>
  <pre class="rust"><code>#[repr(C)]
struct AffordedPoint&lt;const K: usize&gt; {
    distsq_to_cell: f32,
    point: [f32; K],
}

struct SortedAffTree&lt;const K: usize&gt; {
    tests: Box&lt;[f32]&gt;,
    aff_starts: Box&lt;[usize]&gt;,
    affordances: Box&lt;[AffordedPoint&lt;K&gt;]&gt;,
}</code></pre>
  <p>
    Since the distance of each afforded point to the cell is now in ascending order, we can stop
    whenever we see a point which is further from the cell than our query radius.
  </p>
  <pre class="rust"><code>fn sorted_afftree_collides&lt;const K: usize&gt;(
    t: &SortedAffTree&lt;K&gt;,
    point: &[f32; K],
    radius: f32,
) -&gt; bool {
    let id = first_pass(&t.tests, point);
    let rsq = radius * radius;
    t.affordances[t.aff_starts[id]..t.aff_starts[id] + 1]
        .iter()
        .take_while(|p| p.distsq_to_cell &lt;= rsq)
        .any(|p| distsq(&p.point, point) &lt;= rsq)
}</code></pre>
</html>
